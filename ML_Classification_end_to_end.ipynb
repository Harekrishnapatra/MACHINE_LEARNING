{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9cb288f-a338-490a-b65f-4ba3a1361e89",
   "metadata": {},
   "source": [
    "# Model Development without Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4640fc29-df1e-4e17-afcb-dcf33f11b4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv(\"preprocessd_data.csv\")\n",
    "data\n",
    "\n",
    "# Step-2 Devide data into X and y\n",
    "data.shape\n",
    "data.columns\n",
    "  # Churn is the target column\n",
    "X = data.drop(\"churn\",axis=1)\n",
    "y = data[\"churn\"]\n",
    "X.shape,y.shape\n",
    "\n",
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n",
    "\n",
    "# Read and devlop the model\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)\n",
    "\n",
    "# Visualize the model\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "plt.figure(figsize=(10,6))\n",
    "plot_tree(dt,feature_names=X.columns,filled=True,rounded=True)\n",
    "plt.show()\n",
    "\n",
    "# Prediction on test\n",
    "\n",
    "y_pred =dt.predict(X_test)\n",
    "y_pred\n",
    "\n",
    "# Compare with y_test\n",
    "print(y_test.values[:10])\n",
    "print(y_pred[:10])\n",
    "\n",
    "y_test\n",
    "\n",
    "# Create a Predictions Dataframe\n",
    "\n",
    "pred_df = pd.DataFrame()\n",
    "pred_df[\"Ground_Truth_data\"] = y_test\n",
    "pred_df[\"Model_predictions\"] = y_pred\n",
    "l = [1 if i==j else 0 for i,j in zip(y_test,y_pred)]\n",
    "pred_df[\"Match_NotMatch\"]=l\n",
    "accuracy = np.sum(pred_df[\"Match_NotMatch\"])/len(pred_df)\n",
    "accuracy\n",
    "\n",
    "pred_df\n",
    "\n",
    "# Metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,\\\n",
    "                            confusion_matrix,ConfusionMatrixDisplay,roc_auc_score,auc\n",
    "\n",
    "# Confusion Metrix Display\n",
    "\n",
    "confusion_matrix(y_test,y_pred)\n",
    "\n",
    "tn,fp,fn,tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "print(\"true positives are:\",tp)\n",
    "print(\"true negatives are:\",tn)\n",
    "print(\"false positive are:\",fp)\n",
    "print(\"false negative are:\",fn)\n",
    "\n",
    "cmt = confusion_matrix(y_test,y_pred)\n",
    "disp = ConfusionMatrixDisplay(cmt,display_labels=[\"No\",\"Yes\"])\n",
    "disp.plot()\n",
    "\n",
    "# Precision-Recall-F1Score- accuracy\n",
    "\n",
    "pr = round(precision_score(y_test,y_pred),2)\n",
    "rc = round(recall_score(y_test,y_pred),2)\n",
    "acc = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "print(\"The precision score is :\",pr)\n",
    "print(\"The recall score is:\",rc)\n",
    "print(\"The accuracy is:\",acc)\n",
    "print(\"The f1 score is:\",f1)\n",
    "\n",
    "dt_metrics = [pr,rc,acc,f1]\n",
    "metrics_df = pd.DataFrame(dt_metrics,index = [\"Precision\",\"Recall\",\"Accuracy\",\"F1 Score\"],columns=[\"Decision Tree\"])\n",
    "metrics_df\n",
    "\n",
    "prob_yes = dt.predict_proba(X_test)[:,1]\n",
    "prob_yes\n",
    "\n",
    "# ROC Curve\n",
    "y_true = y_test\n",
    "prob_yes = dt.predict_proba(X_test)[:,1]\n",
    "prob_yes\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr,tpr,threshold = roc_curve(y_true,prob_yes)\n",
    "print(\"fpr:\",fpr)\n",
    "print(\"tpr:\",tpr)\n",
    "plt.plot([0,1],[0,1],color=\"navy\",lw=2,label=\"Random-Model\")\n",
    "plt.plot(fpr,tpr,color = \"darkorange\",lw=2,label=\"Decision Tree Model\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristics: ROC-AUC\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# AUC\n",
    "auc_score = auc(fpr,tpr)\n",
    "print(\"The Auc Score is:\",auc_score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0ebb4e-e1bb-4eb6-9b14-e00e250556fc",
   "metadata": {},
   "source": [
    "# Model development using Hyper parameter tunning _ Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8206ee0-6a93-40d1-8457-82f40b821213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix,ConfusionMatrixDisplay,classification_report,roc_auc_score,roc_curve,auc\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv(\"preprocessd_data.csv\")\n",
    "data\n",
    "\n",
    "# Step-2 Devide data into X and y\n",
    "data.shape\n",
    "data.columns\n",
    "  # Churn is the target column\n",
    "X = data.drop(\"churn\",axis=1)\n",
    "y = data[\"churn\"]\n",
    "X.shape,y.shape\n",
    "\n",
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n",
    "\n",
    "# Read the base model\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "gride_tree = DecisionTreeClassifier()\n",
    "gride_tree\n",
    "\n",
    "# Create a parameter file\n",
    "grid_tree.get_params()\n",
    "\n",
    "# You need to create dictionary with hyper parameter\n",
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],   # Splitting criteria for the tree\n",
    "    \"max_depth\": [3, 4, 5, 6, 7, 8],    # Maximum depth of the tree\n",
    "    \"min_samples_split\": [2, 3, 4],     # Minimum samples needed to split a node\n",
    "    \"min_samples_leaf\": [1, 2, 3, 4],   # Minimum samples needed to form a leaf\n",
    "    \"random_state\": [0, 42]             # Seed for reproducibility\n",
    "}\n",
    "\n",
    "# Step-7 Apply Gride Search CV\n",
    "\n",
    "grid_search = GridSearchCV(grid_tree,\n",
    "                           param_grid,\n",
    "                           scoring=\"accuracy\",\n",
    "                           cv=5,\n",
    "                           verbose=True)\n",
    "grid_search\n",
    "\n",
    "dir(grid_search)\n",
    "\n",
    "# Step-8 fit the model with train data\n",
    "\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "# Step-9: Get the best parameters\n",
    "\n",
    "best_params=grid_search.best_params_\n",
    "best_score=grid_search.best_score_\n",
    "print(\"best params:\",best_params)\n",
    "print(\"best train accuracy:\",best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec8c22f-128d-4417-93b9-44cde2a8bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree=DecisionTreeClassifier(criterion='entropy',\n",
    "                            max_depth=6,\n",
    "                            min_samples_leaf=3,\n",
    "                            min_samples_split=2,\n",
    "                            random_state=0)\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# =============================Step-5:  Predictions============================================================\n",
    "\n",
    "y_pred_dt=dtree.predict(X_test)\n",
    "\n",
    "# ============================ Step-6: Metrics==================================================================\n",
    "\n",
    "acc_dt= round(accuracy_score(y_test,y_pred_dt)*100,2)\n",
    "f1_dt=round(f1_score(y_test,y_pred_dt),2)\n",
    "precision_dt=round(precision_score(y_test,y_pred_dt),2)\n",
    "recall_dt=round(recall_score(y_test,y_pred_dt),2)\n",
    "\n",
    "print(\"accuray is:\",acc_dt)\n",
    "print(\"F1 is:\",f1_dt)\n",
    "print(\"Precision is:\",precision_dt)\n",
    "print(\"Recall is:\",recall_dt)\n",
    "print(classification_report(y_test,y_pred_dt))\n",
    "\n",
    "# ================================Step-7:Confusion matrix=========================================================================\n",
    "\n",
    "cmt=confusion_matrix(y_test,y_pred_dt)\n",
    "\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cmt,\n",
    "                            display_labels = [False, True])\n",
    "disp.plot()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred_dt).ravel()\n",
    "print(\"True negative:\",tn)\n",
    "print(\"False postive:\",fp)\n",
    "print(\"False negative:\",fn)\n",
    "print(\"True postive:\",tp)\n",
    "\n",
    "#=======================================Step-8: ROC-AUC curve================================================================\n",
    "\n",
    "y_dt_pred_prob=dtree.predict_proba(X_test)[:,1]   # Class-1 probabilities\n",
    "fpr,tpr,threshold=roc_curve(y_test,y_dt_pred_prob) \n",
    "plt.plot([0,1],[0,1],color=\"navy\",lw=2,label=\"Random-Model\")\n",
    "plt.plot(fpr,tpr,color=\"darkorange\",lw=2, label=\"Decision-Tree Model\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic :ROC-AUC\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Computed Area Under the Curve (AUC)\",auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a18c25a-537d-4869-92c0-5771ab330e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree will provide imprtant features also\n",
    "# Information gain values \n",
    "dtree.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ba0b20-bf8b-44cb-bb94-2f0d70eb7a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_df = pd.DataFrame({\n",
    "    \"Feature Name\": X_train.columns,\n",
    "    \"Importance\": dtree.feature_importances_\n",
    "})\n",
    "fi = imp_df.sort_values(by=\"Importance\", ascending=False)\n",
    "fi\n",
    "\n",
    "# This concept is valid only for DT\n",
    "# you can use these features top 10 again develop the model\n",
    "# Dont use these feature in another model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
